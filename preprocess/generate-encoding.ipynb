{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T22:44:14.374668Z","iopub.execute_input":"2021-11-28T22:44:14.375248Z","iopub.status.idle":"2021-11-28T22:44:14.399140Z","shell.execute_reply.started":"2021-11-28T22:44:14.375154Z","shell.execute_reply":"2021-11-28T22:44:14.398144Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/toy-encoding-data/token_type_ids.txt\n/kaggle/input/toy-encoding-data/input_ids.txt\n/kaggle/input/toy-encoding-data/attention.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nfrom torch.utils.data import TensorDataset, DataLoader\nimport numpy as np\nimport torch\nimport sys\nimport csv\npath_to_dataset = \"/kaggle/input/toy-encoding-data/\"","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:44:15.988373Z","iopub.execute_input":"2021-11-28T22:44:15.989183Z","iopub.status.idle":"2021-11-28T22:44:22.242162Z","shell.execute_reply.started":"2021-11-28T22:44:15.989134Z","shell.execute_reply":"2021-11-28T22:44:22.241450Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"bs = 50\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfilename = 'pooled_'\n    \n    \nprint(\"begin loading tokens\")\ninput_ids = np.loadtxt(path_to_dataset+\"input_ids.txt\")\ntoken_type_ids = np.loadtxt(path_to_dataset+\"token_type_ids.txt\")\nattention_mask = np.loadtxt(path_to_dataset+\"attention.txt\")\nassert input_ids.shape == token_type_ids.shape\nprint(\"tokens loading done\")\n    \ntensor_input_ids = torch.tensor(input_ids).to(torch.int64)\ntensor_token_ids = torch.tensor(token_type_ids).to(torch.int64)\ntensor_attention = torch.tensor(attention_mask).to(torch.int64)\n    \ndataset = TensorDataset(tensor_input_ids, tensor_token_ids, tensor_attention)\ndataloader = DataLoader(dataset, batch_size=bs)\n    \nmodel = AutoModel.from_pretrained(\"bert-base-cased\", output_hidden_states=True)\nmodel.cuda()\nmodel.eval()\n    \ncount = 0\nres = []\nsplit = 1\nfor batch in dataloader:\n    batch = tuple(t.to(device) for t in batch)\n    b_input_ids, b_token_type, b_input_mask = batch\n        \n    with torch.no_grad():\n            \n        outputs = model(b_input_ids, token_type_ids=b_token_type,\n                        attention_mask=b_input_mask)\n        hidden_states = outputs[2]\n        sentence_embedding = torch.mean(hidden_states[-1], dim=1).squeeze()\n        res.append(sentence_embedding.cpu().numpy())\n        count += 1\n        if count == 2000:\n            np.save(filename+str(split)+\".npy\", np.stack(res, axis=0))\n            res = []\n            count = 0\n            split += 1\n    \n    np.save(filename+str(split)+\".npy\", np.stack(res, axis=0))    ","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:44:36.483678Z","iopub.execute_input":"2021-11-28T22:44:36.483930Z","iopub.status.idle":"2021-11-28T22:45:08.392702Z","shell.execute_reply.started":"2021-11-28T22:44:36.483903Z","shell.execute_reply":"2021-11-28T22:45:08.391808Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"begin loading tokens\ntokens loading done\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c91e459860849db9f8409c6aebd3736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dcf850044064ffea075040a9ee6ae02"}},"metadata":{}}]}]}